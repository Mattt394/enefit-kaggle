{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854b4408-4409-443f-90f4-e4a75e8dc6f7",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2066051b-3084-4df6-90b9-4f9fa7a617d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c2edde-1d22-44cb-aa63-c8a52cb3f12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30aee0c5-dfd9-4b3e-b075-78768874b51e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "class TrainDataProcessor:\n",
    "    \"\"\"Processes Train data, using train data as a warm start, and prepares it for inference.\"\"\"\n",
    "\n",
    "    def __init__(self, train, revealed_targets, client, historical_weather,\n",
    "                 forecast_weather, electricity_prices, gas_prices):\n",
    "        self.test_orig_dfs = self.get_test_orig_dfs([train.copy(), revealed_targets.copy(), client.copy(), historical_weather.copy(),\n",
    "                 forecast_weather.copy(), electricity_prices.copy(), gas_prices.copy()])\n",
    "        self.train = self.init_train(train)\n",
    "        self.revealed_targets = self.init_revealed_targets(revealed_targets)\n",
    "        self.client = self.init_client(client)\n",
    "        self.weather_mapping = self.init_weather_mapping()\n",
    "        self.historical_weather = self.init_historical_weather(historical_weather)\n",
    "        self.forecast_weather = self.init_forecast_weather(forecast_weather)\n",
    "        self.electricity_prices = self.init_electricity(electricity_prices)\n",
    "        self.gas_prices = self.init_gas_prices(gas_prices)\n",
    "        \n",
    "        self.df_all_cols = self.join_data(self.train, self.revealed_targets, self.client, self.historical_weather, self.forecast_weather, self.electricity_prices, self.gas_prices)\n",
    "        self.df = self.remove_cols(self.df_all_cols)\n",
    "        \n",
    "    def get_test_orig_dfs(self, dfs):\n",
    "        for i, df in enumerate(dfs):\n",
    "            if 'datetime' in df.columns:\n",
    "                df['datetime'] = pd.to_datetime(df.datetime)\n",
    "                col = 'datetime'\n",
    "            if 'prediction_datetime' in df.columns:\n",
    "                df['prediction_datetime'] = pd.to_datetime(df.prediction_datetime)\n",
    "                col = 'prediction_datetime'\n",
    "            if 'forecast_date' in df.columns:\n",
    "                df['forecast_date'] = pd.to_datetime(df['forecast_date'])\n",
    "                col = 'forecast_date'\n",
    "            if 'forecast_datetime' in df.columns:\n",
    "                df['forecast_datetime'] = pd.to_datetime(df['forecast_datetime'])\n",
    "                col = 'forecast_datetime'\n",
    "            if 'date' in df.columns:\n",
    "                df['date'] = pd.to_datetime(df.date).dt.date\n",
    "                col = 'date'\n",
    "\n",
    "            test_date = df[col].iloc[-1]  # Assuming test is a DataFrame\n",
    "            start_date = test_date - pd.Timedelta(days=14)\n",
    "            historical_subset = df[df[col] >= start_date]\n",
    "            dfs[i] = historical_subset\n",
    "        return dfs\n",
    "        \n",
    "    def init_train(self, df):\n",
    "        \"\"\"Prepares the training data for model training.\"\"\"\n",
    "        try:\n",
    "            df['datetime'] = pd.to_datetime(df.datetime)\n",
    "        except Exception as e:\n",
    "            df['datetime'] = pd.to_datetime(df.prediction_datetime)\n",
    "        df['date'] = df.datetime.dt.date\n",
    "            \n",
    "        # df = self.get_data_block_id(df, 'datetime')\n",
    "        return df\n",
    "    \n",
    "    def add_electricity_lag_features(self, df):\n",
    "        \"\"\"Chatgpt summary:\n",
    "        Enhances a DataFrame with electricity price lag features:\n",
    "        - Sets 'datetime' as Index for time series analysis.\n",
    "        - Calculates rolling 7-day mean price, lagged by one day.\n",
    "        - Computes rolling 7-day mean for same hour, lagged.\n",
    "        - Adds column for yesterday's price, shifted by 24 hours.\n",
    "        - Calculates 24-hour rolling average of electricity prices.\n",
    "        - Resets index and drops 'forecast_date', 'origin_date', 'hour'.\n",
    "        \"\"\"\n",
    "        ##### mean from entire last week\n",
    "        df.set_index('datetime', inplace=True)\n",
    "        # Use rolling to calculate mean price of the last week\n",
    "        # The window is 7 days, min_periods can be set as per requirement\n",
    "        # 'closed' determines which side of the interval is closed; it can be 'right' or 'left'\n",
    "        df['mean_euros_per_mwh_last_week'] = df['euros_per_mwh'].rolling(window='7D', min_periods=1, closed='right').mean()\n",
    "        # Shift the results to align with the requirement of lagging\n",
    "        df['mean_euros_per_mwh_last_week'] = df['mean_euros_per_mwh_last_week'].shift()\n",
    "        \n",
    "        ##### mean from last week this hour only\n",
    "        # Extract hour from datetime\n",
    "        df['hour'] = df.index.hour\n",
    "\n",
    "        # Group by hour and apply rolling mean for each group\n",
    "        hourly_groups = df.groupby('hour')\n",
    "        dff = hourly_groups['euros_per_mwh'].rolling(window='7D', min_periods=1, closed='right').mean()#.shift()#.reset_index(level=0, drop=True)\n",
    "        dff = dff.reset_index().set_index('datetime').groupby('hour')['euros_per_mwh'].shift()\n",
    "        dff = dff.rename('mean_euros_per_mwh_same_hour_last_week')\n",
    "        df = df.join(dff)\n",
    "        #### yesterday's power price\n",
    "        df['yesterdays_euros_per_mwh'] = df['euros_per_mwh'].shift(24)\n",
    "        \n",
    "        ### 24h average\n",
    "        # Calculate the 24-hour rolling average\n",
    "        df['euros_per_mwh_24h_average_price'] = df['euros_per_mwh'].rolling(window=24, min_periods=1).mean()\n",
    "\n",
    "        # Resetting the index if needed\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df.drop(['forecast_date', 'origin_date', 'hour'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def init_electricity(self, df):\n",
    "        ## LAG = 1 Day\n",
    "        ## Move forecast datetime ahead by 1 day\n",
    "        ## change name to datetime\n",
    "        df['datetime'] = pd.to_datetime(df['forecast_date'])\n",
    "        df['datetime'] = df['datetime'] + dt.timedelta(days=1)\n",
    "        # df = self.get_data_block_id(df, 'datetime')\n",
    "        df = self.add_electricity_lag_features(df)\n",
    "        return df\n",
    "    \n",
    "    def add_historical_weather_lag_features(self, df):\n",
    "        \"\"\"Chatgpt summary:\n",
    "        Enhances a DataFrame with historical weather lag features:\n",
    "        - Converts 'datetime' to Datetime object and sets as index.\n",
    "        - Sorts data by 'datetime', 'latitude', 'longitude'.\n",
    "        - Creates 'location_id' as a unique identifier for each location.\n",
    "        - Filters for 10:00 AM entries and shifts features by 1 day.\n",
    "        - Merges lagged features with original DataFrame.\n",
    "        - Calculates mean and variance for weather features over the last 24 hours.\n",
    "        - Merges these statistical summaries back into the original DataFrame.\n",
    "        \"\"\"\n",
    "        ##### LATEST WEATHER\n",
    "        def add_latest_weather(df):\n",
    "            # Assuming df is your original DataFrame\n",
    "            # Step 1: Convert datetime to a Datetime Object\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df.set_index('datetime', inplace=True)\n",
    "\n",
    "            # Step 2: Sorting the Data\n",
    "            df.sort_values(by=['datetime', 'latitude', 'longitude'], inplace=True)\n",
    "\n",
    "            # Step 3: Creating a Unique Identifier for each location\n",
    "            df['location_id'] = df['latitude'].astype(str) + '_' + df['longitude'].astype(str)\n",
    "\n",
    "            # Step 4: Filtering for 10:00 AM Entries\n",
    "            df.reset_index(inplace=True)\n",
    "            df_10am = df[df['datetime'].dt.hour == 10]\n",
    "            df_10am.set_index('datetime', inplace=True)\n",
    "\n",
    "            # Step 5: Shifting the Features by 1 day\n",
    "            lagged_features = df_10am.groupby('location_id').shift(periods=1, freq='D')\n",
    "\n",
    "            # Renaming columns to indicate lag\n",
    "            lagged_features = lagged_features.add_suffix('_hw_lagged')\n",
    "            lagged_features['location_id'] = lagged_features['location_id_hw_lagged']\n",
    "            lagged_features.reset_index(inplace=True)\n",
    "            lagged_features['date'] = lagged_features.datetime.dt.date\n",
    "\n",
    "            df['date'] = df.datetime.dt.date\n",
    "            return lagged_features\n",
    "            # Step 6: Merging Lagged Features with Original DataFrame\n",
    "            df = df.merge(lagged_features, on=['date', 'location_id'], how='left', suffixes=('', '_hw_lagged'))\n",
    "            return df\n",
    "        \n",
    "        ##### mean from last day\n",
    "        def add_24h_mean_var(df, weather_features):\n",
    "            # Calculate the start and end times for each row\n",
    "            df['start_time'] = pd.to_datetime(df['datetime'].dt.date) - pd.Timedelta(days=2) + pd.Timedelta(hours=11)\n",
    "            df['end_time'] = pd.to_datetime(df['datetime'].dt.date) - pd.Timedelta(days=1) + pd.Timedelta(hours=10)\n",
    "            df['time_code'] = df['start_time'].astype(str) +'_' + df['end_time'].astype(str) + '_' + df['latitude'].astype(str) + '_' + df['longitude'].astype(str)\n",
    "            # print(df.time_code)\n",
    "\n",
    "            # Create a helper column for grouping\n",
    "            # If the time is before 10:00 AM, subtract a day\n",
    "            df['group'] = df['datetime'].apply(lambda dt: dt if dt.time() >= pd.to_datetime('11:00').time() else dt - pd.Timedelta(days=1))\n",
    "            df['group'] = df['group'].dt.date  # Keep only the date part for grouping\n",
    "            df['group'] = (pd.to_datetime(df['group']) + pd.Timedelta(hours=11)).astype(str) + '_' + (pd.to_datetime(df['group']) + pd.Timedelta(days=1, hours=10)).astype(str) + '_' + df['latitude'].astype(str) + '_' + df['longitude'].astype(str)\n",
    "\n",
    "            # Now group by this new column\n",
    "            grouped = df.groupby('group')\n",
    "            means = grouped[weather_features].mean()\n",
    "            variances = grouped[weather_features].var()\n",
    "\n",
    "            # Merge means and variances into the original DataFrame\n",
    "            my_df = df.merge(means, left_on='time_code', right_on='group', suffixes=('', '_hw_means'), how='left')\n",
    "            my_df = my_df.merge(variances, left_on='time_code', right_on='group', how='left', suffixes=('', '_hw_variances'))\n",
    "\n",
    "            return my_df\n",
    "\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        weather_features = df.columns.drop(['datetime', 'latitude', 'longitude'])\n",
    "\n",
    "        # Apply the function\n",
    "        df = add_24h_mean_var(df, weather_features)       \n",
    "        latest = add_latest_weather(df)\n",
    "        df = df.merge(latest, on=['date', 'location_id'], how='left', suffixes=('', '_hw_lagged'))\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def init_historical_weather(self, df):\n",
    "        ## LAG: From 11:00 AM 2 days ago to 10:00 AM 1 day ago\n",
    "        ## What to do? Give most recent weather forecast? Give average over the last day?\n",
    "        \"\"\"\n",
    "        Processes the historical weather data.\n",
    "        \"\"\"\n",
    "        df['datetime'] = pd.to_datetime(df.datetime)\n",
    "        \n",
    "        df = self.add_historical_weather_lag_features(df)\n",
    "        \n",
    "        df = df.merge(self.weather_mapping, how='inner', on=('latitude', 'longitude'))\n",
    "        return df\n",
    "\n",
    "    def init_forecast_weather(self, df):\n",
    "        \"\"\"Chatgpt summary:\n",
    "        Processes forecast weather data:\n",
    "        - Converts 'forecast_datetime' to 'datetime' and adjusts it forward by 1 day.\n",
    "        - Filters data to keep records with 'hours_ahead' between 22 and 45.\n",
    "        - Merges with a weather mapping based on 'latitude' and 'longitude'.\n",
    "        \"\"\"\n",
    "        ## LAG: DON't ADJUST\n",
    "        ##      The forecast is from yesterday, but can forecast today, which is 22 hours ahead\n",
    "        ## Drop any columns where:\n",
    "        ##                        hours_ahead < 22 and hours_ahead > 45\n",
    "        ## Then rename forecast_datetime to datetime and join on datetime\n",
    "        \"\"\"\n",
    "        Processes the forecast weather data.\n",
    "        \"\"\"\n",
    "        df['datetime'] = pd.to_datetime(df['forecast_datetime'])\n",
    "        # keep only datetimes from our relevant period\n",
    "        df = df[(df['hours_ahead'] < 46) & (df['hours_ahead'] > 21)]\n",
    "        df['datetime'] = df['datetime'] + dt.timedelta(days=1)\n",
    "        df = df.merge(self.weather_mapping, how='inner', on=('latitude', 'longitude'))\n",
    "        return df\n",
    "    \n",
    "    def add_gas_prices_lag_features(self, df):\n",
    "        \"\"\"Chatgpt summary\n",
    "        Augments a DataFrame with rolling average lag features for gas prices:\n",
    "        - Converts 'date' to Datetime object and sets as index.\n",
    "        - Sorts DataFrame by date.\n",
    "        - Calculates rolling averages for lowest and highest gas prices over 3, 7, and 14 days.\n",
    "        - Resets the index to include 'date' as a column again.\n",
    "        \"\"\"\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df.set_index('date', inplace=True)\n",
    "\n",
    "        # Sort the DataFrame by date, if it's not already sorted\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "        # Calculate rolling averages for different time windows\n",
    "        df['lowest_price_3d_avg'] = df['lowest_price_per_mwh'].rolling(window=3).mean()\n",
    "        df['highest_price_3d_avg'] = df['highest_price_per_mwh'].rolling(window=3).mean()\n",
    "\n",
    "        df['lowest_price_7d_avg'] = df['lowest_price_per_mwh'].rolling(window=7).mean()\n",
    "        df['highest_price_7d_avg'] = df['highest_price_per_mwh'].rolling(window=7).mean()\n",
    "\n",
    "        df['lowest_price_14d_avg'] = df['lowest_price_per_mwh'].rolling(window=14).mean()\n",
    "        df['highest_price_14d_avg'] = df['highest_price_per_mwh'].rolling(window=14).mean()\n",
    "\n",
    "        # Reset the index if you want the 'date' column back\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "\n",
    "    def init_gas_prices(self, df):\n",
    "        ## LAG: 1 DAY\n",
    "        ## Predictions are made from 2 days ago and predict for yesterday\n",
    "        ## add one day to forecast_date\n",
    "        ## Rename forecast_date to date, join on date\n",
    "        \"\"\"\n",
    "        Processes the gas prices data.\n",
    "        Implement the logic to handle gas prices data processing here.\n",
    "        \"\"\"\n",
    "        df['date'] = pd.to_datetime(df['forecast_date']).dt.date\n",
    "        df['date'] = df['date'] + dt.timedelta(days=1)\n",
    "        df = self.add_gas_prices_lag_features(df)\n",
    "        return df\n",
    "    \n",
    "    def add_revealed_target_features(self, df):\n",
    "        \"\"\"Chatgpt summary:\n",
    "        Enhances DataFrame with rolling average target features:\n",
    "        - Converts 'datetime' to Datetime object, extracts 'hour' and 'day' of week.\n",
    "        - Sets 'datetime' as index.\n",
    "        - Calculates various rolling averages of 'target' based on different groupings:\n",
    "          - 24-hour rolling average by county, business status, product type, and consumption status.\n",
    "          - 7-day hourly rolling average by county, business status, product type, consumption status, and hour.\n",
    "          - 4-week rolling average by county, business status, product type, consumption status, hour, and day.\n",
    "          - Similar calculations considering all product types.\n",
    "        - Drops 'hour' and 'day' columns after processing.\n",
    "        \"\"\"\n",
    "        df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "        df['hour'] = df.datetime.dt.hour\n",
    "        df['day'] = df.datetime.dt.dayofweek\n",
    "        df.set_index('datetime', inplace=True)\n",
    "\n",
    "        window_size = 7\n",
    "        # Group by the specified columns and then apply the rolling mean\n",
    "        grouped = df.groupby(['county', 'is_business', 'product_type', 'is_consumption'])\n",
    "        df['target_rolling_avg_24h'] = grouped['target'].transform(lambda x: x.rolling(window=24, min_periods=1).mean())\n",
    "\n",
    "        grouped = df.groupby(['county', 'is_business', 'product_type', 'is_consumption', 'hour'])\n",
    "        df['target_rolling_avg_hour_7d'] = grouped['target'].transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    "\n",
    "        grouped = df.groupby(['county', 'is_business', 'product_type', 'is_consumption', 'hour', 'day'])\n",
    "        df['target_rolling_avg_hour_hour_day_4w'] = grouped['target'].transform(lambda x: x.rolling(window=4, min_periods=1).mean())\n",
    "\n",
    "        grouped = df.groupby(['county', 'is_business', 'is_consumption'])\n",
    "        df['target_rolling_allp_avg_24h'] = grouped['target'].transform(lambda x: x.rolling(window=24, min_periods=1).mean())\n",
    "\n",
    "        grouped = df.groupby(['county', 'is_business', 'is_consumption', 'hour'])\n",
    "        df['target_rolling_allp_avg_hour_7d'] = grouped['target'].transform(lambda x: x.rolling(window=7, min_periods=1).mean())\n",
    "\n",
    "        grouped = df.groupby(['county', 'is_business', 'is_consumption', 'hour', 'day'])\n",
    "        df['target_rolling_allp_avg_hour_hour_day_4w'] = grouped['target'].transform(lambda x: x.rolling(window=4, min_periods=1).mean())\n",
    "        \n",
    "        df = df.drop(['hour', 'day'], axis=1)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def init_revealed_targets(self, df):\n",
    "        df['datetime'] = pd.to_datetime(df.datetime)\n",
    "        df['datetime'] = df['datetime'] + dt.timedelta(days=2)\n",
    "        df = self.add_revealed_target_features(df)\n",
    "        return df\n",
    "    \n",
    "    def init_client(self, df):\n",
    "        ## LAG: 2 days\n",
    "        ## Add 2 days to date, join on date\n",
    "        df['date'] = pd.to_datetime(df.date).dt.date\n",
    "        df['date'] = df['date'] + dt.timedelta(days=2)\n",
    "        # df = self.get_data_block_id(df, 'date')\n",
    "        return df\n",
    "\n",
    "    def init_weather_mapping(self):\n",
    "        # https://www.kaggle.com/code/tsunotsuno/enefit-eda-baseline/notebook#Baseline\n",
    "        county_point_map = {\n",
    "            0: (59.4, 24.7), # \"HARJUMAA\"\n",
    "            1 : (58.8, 22.7), # \"HIIUMAA\"\n",
    "            2 : (59.1, 27.2), # \"IDA-VIRUMAA\"\n",
    "            3 : (58.8, 25.7), # \"JÄRVAMAA\"\n",
    "            4 : (58.8, 26.2), # \"JÕGEVAMAA\"\n",
    "            5 : (59.1, 23.7), # \"LÄÄNE-VIRUMAA\"\n",
    "            6 : (59.1, 23.7), # \"LÄÄNEMAA\"\n",
    "            7 : (58.5, 24.7), # \"PÄRNUMAA\"\n",
    "            8 : (58.2, 27.2), # \"PÕLVAMAA\"\n",
    "            9 : (58.8, 24.7), # \"RAPLAMAA\"\n",
    "            10 : (58.5, 22.7),# \"SAAREMAA\"\n",
    "            11 : (58.5, 26.7),# \"TARTUMAA\"\n",
    "            12 : (58.5, 25.2),# \"UNKNOWNN\" (center of the map)\n",
    "            13 : (57.9, 26.2),# \"VALGAMAA\"\n",
    "            14 : (58.2, 25.7),# \"VILJANDIMAA\"\n",
    "            15 : (57.9, 27.2) # \"VÕRUMAA\"\n",
    "        }\n",
    "        # Convert the dictionary to a list of tuples\n",
    "        data = [(county_code, lat, lon) for county_code, (lat, lon) in county_point_map.items()]\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=['county', 'latitude', 'longitude'])\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_date_features(self, df):\n",
    "        df['year'] = df['datetime'].dt.year\n",
    "        df['month'] = df['datetime'].dt.month\n",
    "        df['day'] = df['datetime'].dt.day\n",
    "        df['hour'] = df['datetime'].dt.hour\n",
    "        df['quarter'] = df['datetime'].dt.quarter\n",
    "        df['day_of_week'] = df['datetime'].dt.day_of_week\n",
    "        df['day_of_year'] = df['datetime'].dt.dayofyear\n",
    "        df['week_of_year'] = df['datetime'].dt.isocalendar().week\n",
    "        df['is_weekend'] = df['datetime'].dt.day_of_week >= 5\n",
    "        df['is_month_start'] = df['datetime'].dt.is_month_start\n",
    "        df['is_month_end'] = df['datetime'].dt.is_month_end\n",
    "        df['is_quarter_start'] = df['datetime'].dt.is_quarter_start\n",
    "        df['is_quarter_end'] = df['datetime'].dt.is_quarter_end\n",
    "        df['is_year_start'] = df['datetime'].dt.is_year_start\n",
    "        df['is_year_end'] = df['datetime'].dt.is_year_end\n",
    "        df['season'] = df['datetime'].dt.month % 12 // 3 + 1\n",
    "        df['hour_sin'] = np.sin(df['datetime'].dt.hour * (2. * np.pi / 24))\n",
    "        df['hour_cos'] = np.cos(df['datetime'].dt.hour * (2. * np.pi / 24))\n",
    "        # Calculate sin and cos for day of year\n",
    "        days_in_year = 365.25  # accounts for leap year\n",
    "        df['day_of_year_sin'] = np.sin((df['day_of_year'] - 1) * (2 * np.pi / days_in_year))\n",
    "        df['day_of_year_cos'] = np.cos((df['day_of_year'] - 1) * (2 * np.pi / days_in_year))\n",
    "        return df\n",
    "    \n",
    "    def add_ee_holidays(self, df):\n",
    "        import holidays\n",
    "        # Define Estonia public holidays\n",
    "        ee_holidays = holidays.CountryHoliday('EE')\n",
    "        \n",
    "        print(df['date'].isna().sum())\n",
    "        \n",
    "        def find_problem(x):\n",
    "            try:\n",
    "                return x in ee_holidays\n",
    "            except Exception as e:\n",
    "                print(x)\n",
    "                raise e\n",
    "\n",
    "        # Function to check if the date is a holiday\n",
    "        df['is_ee_holiday'] = df['date'].apply(lambda x: x in ee_holidays)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def remove_cols(self, df):\n",
    "        col_list = ['datetime',\n",
    "                   'row_id',\n",
    "                   'prediction_unit_id',\n",
    "                    'date_train',\n",
    "                    'hour_part',\n",
    "                   'date_client',\n",
    "                    'forecast_date_elec_price',\n",
    "                    'origin_date_elec_price',\n",
    "                    'forecast_date_gas_price',\n",
    "                    'origin_date_gas_price',\n",
    "                    'datetime_hist_weath',\n",
    "                   'hour_part_hist_weath_latest',\n",
    "                    'datetime_hist_weath_latest',\n",
    "                   'origin_datetime',\n",
    "                   'hour_part_fore_weath',\n",
    "                    'datetime',\n",
    "                     'data_block_id',\n",
    "                     'row_id',\n",
    "                     'prediction_unit_id',\n",
    "                     'date',\n",
    "                    'data_block_id_rt',\n",
    "                     'row_id_rt',\n",
    "                     'prediction_unit_id_rt',\n",
    "                    'data_block_id_client',\n",
    "                    'latitude',\n",
    "                     'longitude',\n",
    "                     'data_block_id_hw',\n",
    "                    'start_time',\n",
    "                     'end_time',\n",
    "                     'time_code',\n",
    "                     'group',\n",
    "                    'data_block_id_hw_means',\n",
    "                    'data_block_id_hw_variances',\n",
    "                     'location_id',\n",
    "                     'date_hw',\n",
    "                     'datetime_hw_lagged',\n",
    "                    'latitude_hw_lagged',\n",
    "                     'longitude_hw_lagged',\n",
    "                     'data_block_id_hw_lagged',\n",
    "                     'start_time_hw_lagged',\n",
    "                     'end_time_hw_lagged',\n",
    "                     'time_code_hw_lagged',\n",
    "                     'group_hw_lagged',\n",
    "                    'data_block_id_hw_means_hw_lagged',\n",
    "                    'data_block_id_hw_variances_hw_lagged',\n",
    "                    'location_id_hw_lagged',\n",
    "                     'latitude_fw',\n",
    "                     'longitude_fw',\n",
    "                     'origin_datetime',\n",
    "                    'data_block_id_fw',\n",
    "                     'forecast_datetime',\n",
    "                    'data_block_id_elec',\n",
    "                    'forecast_date',\n",
    "                    'origin_date',\n",
    "                     'data_block_id_gasp',\n",
    "                   ]\n",
    "        columns_to_drop = [col for col in col_list if col in df.columns]\n",
    "        df = df.drop(columns_to_drop, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def remove_test_cols(self, df):\n",
    "        col_list = ['datetime',\n",
    "                   'prediction_unit_id',\n",
    "                    'date_train',\n",
    "                    'hour_part',\n",
    "                   'date_client',\n",
    "                    'forecast_date_elec_price',\n",
    "                    'origin_date_elec_price',\n",
    "                    'forecast_date_gas_price',\n",
    "                    'origin_date_gas_price',\n",
    "                    'datetime_hist_weath',\n",
    "                   'hour_part_hist_weath_latest',\n",
    "                    'datetime_hist_weath_latest',\n",
    "                   'origin_datetime',\n",
    "                   'hour_part_fore_weath',\n",
    "                    'datetime',\n",
    "                     'data_block_id',\n",
    "                     'prediction_unit_id',\n",
    "                     'date',\n",
    "                    'data_block_id_rt',\n",
    "                     'row_id_rt',\n",
    "                     'prediction_unit_id_rt',\n",
    "                    'data_block_id_client',\n",
    "                    'latitude',\n",
    "                     'longitude',\n",
    "                     'data_block_id_hw',\n",
    "                    'start_time',\n",
    "                     'end_time',\n",
    "                     'time_code',\n",
    "                     'group',\n",
    "                    'data_block_id_hw_means',\n",
    "                    'data_block_id_hw_variances',\n",
    "                     'location_id',\n",
    "                     'date_hw',\n",
    "                     'datetime_hw_lagged',\n",
    "                    'latitude_hw_lagged',\n",
    "                     'longitude_hw_lagged',\n",
    "                     'data_block_id_hw_lagged',\n",
    "                     'start_time_hw_lagged',\n",
    "                     'end_time_hw_lagged',\n",
    "                     'time_code_hw_lagged',\n",
    "                     'group_hw_lagged',\n",
    "                    'data_block_id_hw_means_hw_lagged',\n",
    "                    'data_block_id_hw_variances_hw_lagged',\n",
    "                    'location_id_hw_lagged',\n",
    "                     'latitude_fw',\n",
    "                     'longitude_fw',\n",
    "                     'origin_datetime',\n",
    "                    'data_block_id_fw',\n",
    "                     'forecast_datetime',\n",
    "                    'data_block_id_elec',\n",
    "                    'forecast_date',\n",
    "                    'origin_date',\n",
    "                     'data_block_id_gasp',\n",
    "                   ]\n",
    "        columns_to_drop = [col for col in col_list if col in df.columns]\n",
    "        df = df.drop(columns_to_drop, axis=1)\n",
    "        return df\n",
    "    \n",
    "    def join_data(self, train, revealed_targets, client, historical_weather, forecast_weather, electricity_prices, gas_prices):\n",
    "        df = train\n",
    "        df = df.merge(revealed_targets, how='left', on=('datetime', 'county', 'is_business', 'product_type', 'is_consumption'), suffixes=('', '_rt'))\n",
    "        df = df.merge(client, how='left', on=('date', 'county', 'is_business', 'product_type'), suffixes=('', '_client'))\n",
    "        df = df.merge(historical_weather, how='left', on=('datetime', 'county'), suffixes=('', '_hw'))\n",
    "        df = df.merge(forecast_weather, how='left', on=('datetime', 'county'), suffixes=('', '_fw'))\n",
    "        df = df.merge(electricity_prices, how='left', on='datetime', suffixes=('', '_elec'))\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df = df.merge(gas_prices, how='left', on='date', suffixes=('', '_gasp'))\n",
    "        df = self.add_date_features(df)\n",
    "        df = self.add_ee_holidays(df)\n",
    "        return df\n",
    "    \n",
    "    def add_test_data(self, test, revealed_targets, client, historical_weather,\n",
    "            forecast_weather, electricity_prices, gas_prices):\n",
    "        dfs = [test.copy(), revealed_targets.copy(), client.copy(), historical_weather.copy(),\n",
    "                 forecast_weather.copy(), electricity_prices.copy(), gas_prices.copy()]\n",
    "        for i, df in enumerate(dfs):\n",
    "            if 'datetime' in df.columns:\n",
    "                df['datetime'] = pd.to_datetime(df.datetime)\n",
    "                col = 'datetime'\n",
    "            if 'prediction_datetime' in df.columns:\n",
    "                df['datetime'] = pd.to_datetime(df.prediction_datetime)\n",
    "                col = 'datetime'\n",
    "            if 'forecast_date' in df.columns:\n",
    "                df['forecast_date'] = pd.to_datetime(df['forecast_date'])\n",
    "                col = 'forecast_date'\n",
    "            if 'forecast_datetime' in df.columns:\n",
    "                df['forecast_datetime'] = pd.to_datetime(df['forecast_datetime'])\n",
    "                col = 'forecast_datetime'\n",
    "                \n",
    "            self.test_orig_dfs[i] = pd.concat([ self.test_orig_dfs[i], df ])          \n",
    "        \n",
    "        \n",
    "    \n",
    "    def process_test_data_timestep(self, test, revealed_targets, client, historical_weather,\n",
    "            forecast_weather, electricity_prices, gas_prices):\n",
    "        #append test data to test data cache\n",
    "        self.add_test_data(test, revealed_targets, client, historical_weather,\n",
    "            forecast_weather, electricity_prices, gas_prices)\n",
    "        # process test data\n",
    "        test = self.init_train(self.test_orig_dfs[0].copy())\n",
    "        revealed_targets = self.init_revealed_targets(self.test_orig_dfs[1].copy())\n",
    "        client = self.init_client(self.test_orig_dfs[2].copy())\n",
    "        historical_weather = self.init_historical_weather(self.test_orig_dfs[3].copy())\n",
    "        forecast_weather = self.init_forecast_weather(self.test_orig_dfs[4].copy())\n",
    "        electricity_prices = self.init_electricity(self.test_orig_dfs[5].copy())\n",
    "        gas_prices = self.init_gas_prices(self.test_orig_dfs[6].copy())\n",
    "        \n",
    "        df_all_cols = self.join_data(test, revealed_targets, client, historical_weather,\n",
    "            forecast_weather, electricity_prices, gas_prices)\n",
    "        df = self.remove_test_cols(df_all_cols)\n",
    "        return df\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f1783a1-aaa1-4857-b335-99b1308ccef0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>target_rt</th>\n",
       "      <th>target_lag_1h</th>\n",
       "      <th>target_lag_2h</th>\n",
       "      <th>target_lag_3h</th>\n",
       "      <th>target_lag_4h</th>\n",
       "      <th>...</th>\n",
       "      <th>is_quarter_start</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>season</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "      <th>is_ee_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861693</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96.590</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861693</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861693</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.314</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861693</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.904</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.861693</td>\n",
       "      <td>-0.507430</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018609</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197.233</td>\n",
       "      <td>1</td>\n",
       "      <td>184.072</td>\n",
       "      <td>171.092</td>\n",
       "      <td>168.933</td>\n",
       "      <td>174.920</td>\n",
       "      <td>170.068</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018610</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.501</td>\n",
       "      <td>25.884</td>\n",
       "      <td>83.535</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018611</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.404</td>\n",
       "      <td>1</td>\n",
       "      <td>38.646</td>\n",
       "      <td>47.690</td>\n",
       "      <td>34.806</td>\n",
       "      <td>29.202</td>\n",
       "      <td>21.654</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018612</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.512</td>\n",
       "      <td>34.657</td>\n",
       "      <td>122.195</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018613</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>196.240</td>\n",
       "      <td>1</td>\n",
       "      <td>183.756</td>\n",
       "      <td>190.316</td>\n",
       "      <td>172.973</td>\n",
       "      <td>141.646</td>\n",
       "      <td>93.817</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2018614 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county  is_business  product_type   target  is_consumption  \\\n",
       "0             0            0             1    0.713               0   \n",
       "1             0            0             1   96.590               1   \n",
       "2             0            0             2    0.000               0   \n",
       "3             0            0             2   17.314               1   \n",
       "4             0            0             3    2.904               0   \n",
       "...         ...          ...           ...      ...             ...   \n",
       "2018609      15            1             0  197.233               1   \n",
       "2018610      15            1             1    0.000               0   \n",
       "2018611      15            1             1   28.404               1   \n",
       "2018612      15            1             3    0.000               0   \n",
       "2018613      15            1             3  196.240               1   \n",
       "\n",
       "         target_rt  target_lag_1h  target_lag_2h  target_lag_3h  \\\n",
       "0              NaN            NaN            NaN            NaN   \n",
       "1              NaN            NaN            NaN            NaN   \n",
       "2              NaN            NaN            NaN            NaN   \n",
       "3              NaN            NaN            NaN            NaN   \n",
       "4              NaN            NaN            NaN            NaN   \n",
       "...            ...            ...            ...            ...   \n",
       "2018609    184.072        171.092        168.933        174.920   \n",
       "2018610      0.000          0.000          2.501         25.884   \n",
       "2018611     38.646         47.690         34.806         29.202   \n",
       "2018612      0.000          0.000          4.512         34.657   \n",
       "2018613    183.756        190.316        172.973        141.646   \n",
       "\n",
       "         target_lag_4h  ...  is_quarter_start  is_quarter_end  is_year_start  \\\n",
       "0                  NaN  ...             False           False          False   \n",
       "1                  NaN  ...             False           False          False   \n",
       "2                  NaN  ...             False           False          False   \n",
       "3                  NaN  ...             False           False          False   \n",
       "4                  NaN  ...             False           False          False   \n",
       "...                ...  ...               ...             ...            ...   \n",
       "2018609        170.068  ...             False           False          False   \n",
       "2018610         83.535  ...             False           False          False   \n",
       "2018611         21.654  ...             False           False          False   \n",
       "2018612        122.195  ...             False           False          False   \n",
       "2018613         93.817  ...             False           False          False   \n",
       "\n",
       "         is_year_end  season  hour_sin  hour_cos  day_of_year_sin  \\\n",
       "0              False       4  0.000000  1.000000        -0.861693   \n",
       "1              False       4  0.000000  1.000000        -0.861693   \n",
       "2              False       4  0.000000  1.000000        -0.861693   \n",
       "3              False       4  0.000000  1.000000        -0.861693   \n",
       "4              False       4  0.000000  1.000000        -0.861693   \n",
       "...              ...     ...       ...       ...              ...   \n",
       "2018609        False       2 -0.258819  0.965926         0.532227   \n",
       "2018610        False       2 -0.258819  0.965926         0.532227   \n",
       "2018611        False       2 -0.258819  0.965926         0.532227   \n",
       "2018612        False       2 -0.258819  0.965926         0.532227   \n",
       "2018613        False       2 -0.258819  0.965926         0.532227   \n",
       "\n",
       "         day_of_year_cos  is_ee_holiday  \n",
       "0              -0.507430          False  \n",
       "1              -0.507430          False  \n",
       "2              -0.507430          False  \n",
       "3              -0.507430          False  \n",
       "4              -0.507430          False  \n",
       "...                  ...            ...  \n",
       "2018609        -0.846602          False  \n",
       "2018610        -0.846602          False  \n",
       "2018611        -0.846602          False  \n",
       "2018612        -0.846602          False  \n",
       "2018613        -0.846602          False  \n",
       "\n",
       "[2018614 rows x 240 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data_processor_lgbm2_new_pandas.pkl', 'rb') as f:\n",
    "    data_processor = pickle.load(f)\n",
    "data_processor.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab57e681-f170-4287-8b80-002e80e12839",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe2a4a2-ac48-48d6-a8d6-b9e3563e4760",
   "metadata": {},
   "source": [
    "For my experimental CV, I want to take the approach of doing a stratified CV by time - splitting the year into 4 different parts, basically testing the model on each season, 3 months at a time. There was something in the kaggle forums that recommended something like this:\n",
    "\n",
    "Key: \n",
    "= -> training data\n",
    "+ -> CV data\n",
    "\n",
    "4 splits in time:\n",
    "1. =============+++\n",
    "2. ================+++\n",
    "3. ===================+++\n",
    "4. ======================+++\n",
    "\n",
    "\n",
    "\n",
    "The data starts on 2021-09-01 and ends on 2023-05-31\n",
    "\n",
    "BUT we don't have enough data to do that properly. So, my CV will instead be:\n",
    "\n",
    "\n",
    "(Thanks chatgpt)\n",
    "\n",
    "Splitting the period from 2022-09-01 to 2023-05-31 into five equal parts, here are the date ranges for each segment:\n",
    "\n",
    "#### First Segment:\n",
    "\n",
    "From 2022-09-01 to 2022-10-24\n",
    "\n",
    "#### Second Segment:\n",
    "\n",
    "From 2022-10-25 to 2022-12-17\n",
    "\n",
    "#### Third Segment:\n",
    "\n",
    "From 2022-12-18 to 2023-02-09\n",
    "\n",
    "#### Fourth Segment:\n",
    "\n",
    "From 2023-02-10 to 2023-04-04\n",
    "\n",
    "#### Fifth Segment:\n",
    "\n",
    "From 2023-04-05 to 2023-05-29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1505e0-cc5e-4cfb-90b8-f82f9034cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb95938-f64f-4509-ad4b-e9075698b721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_drop_na(df):\n",
    "    df = df[~df.target.isna()]\n",
    "    df = df[~df.target_rolling_avg_24h.isna()]\n",
    "    means = df.mean()\n",
    "    # For each column, add an indicator column for NA values\n",
    "    # for col in df.columns:\n",
    "    #     if df[col].isna().any():\n",
    "    #         df[f'{col}_is_na'] = df[col].isna()\n",
    "    df = df.fillna(means)\n",
    "    return df, means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5b7aef-e1ac-4067-831a-dded4567605a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.03 s\n",
      "Wall time: 14.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "county             0\n",
       "is_business        0\n",
       "product_type       0\n",
       "target             0\n",
       "is_consumption     0\n",
       "                  ..\n",
       "hour_sin           0\n",
       "hour_cos           0\n",
       "day_of_year_sin    0\n",
       "day_of_year_cos    0\n",
       "is_ee_holiday      0\n",
       "Length: 240, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "processed_df_no_na, means = fill_drop_na(data_processor.df)\n",
    "processed_df_no_na.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8583e570-0b4f-4156-81da-cbd66807dc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mskel\\AppData\\Local\\Temp\\ipykernel_22924\\2244001451.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  processed_df_no_na['target_installed_capacity'] = processed_df_no_na['target'] / processed_df_no_na['installed_capacity'] * 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>target_rt</th>\n",
       "      <th>target_lag_1h</th>\n",
       "      <th>target_lag_2h</th>\n",
       "      <th>target_lag_3h</th>\n",
       "      <th>target_lag_4h</th>\n",
       "      <th>...</th>\n",
       "      <th>is_quarter_end</th>\n",
       "      <th>is_year_start</th>\n",
       "      <th>is_year_end</th>\n",
       "      <th>season</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>day_of_year_sin</th>\n",
       "      <th>day_of_year_cos</th>\n",
       "      <th>is_ee_holiday</th>\n",
       "      <th>target_installed_capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11712</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>274.689353</td>\n",
       "      <td>274.69907</td>\n",
       "      <td>274.708302</td>\n",
       "      <td>274.717501</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.894542</td>\n",
       "      <td>-0.446983</td>\n",
       "      <td>False</td>\n",
       "      <td>0.975978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123.214</td>\n",
       "      <td>1</td>\n",
       "      <td>96.590</td>\n",
       "      <td>274.689353</td>\n",
       "      <td>274.69907</td>\n",
       "      <td>274.708302</td>\n",
       "      <td>274.717501</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.894542</td>\n",
       "      <td>-0.446983</td>\n",
       "      <td>False</td>\n",
       "      <td>129.305586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>274.689353</td>\n",
       "      <td>274.69907</td>\n",
       "      <td>274.708302</td>\n",
       "      <td>274.717501</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.894542</td>\n",
       "      <td>-0.446983</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21.940</td>\n",
       "      <td>1</td>\n",
       "      <td>17.314</td>\n",
       "      <td>274.689353</td>\n",
       "      <td>274.69907</td>\n",
       "      <td>274.708302</td>\n",
       "      <td>274.717501</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.894542</td>\n",
       "      <td>-0.446983</td>\n",
       "      <td>False</td>\n",
       "      <td>131.850962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.611</td>\n",
       "      <td>0</td>\n",
       "      <td>2.904</td>\n",
       "      <td>274.689353</td>\n",
       "      <td>274.69907</td>\n",
       "      <td>274.708302</td>\n",
       "      <td>274.717501</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.894542</td>\n",
       "      <td>-0.446983</td>\n",
       "      <td>False</td>\n",
       "      <td>0.223505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018609</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>197.233</td>\n",
       "      <td>1</td>\n",
       "      <td>184.072</td>\n",
       "      <td>171.092000</td>\n",
       "      <td>168.93300</td>\n",
       "      <td>174.920000</td>\n",
       "      <td>170.068000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "      <td>318.117742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018610</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.50100</td>\n",
       "      <td>25.884000</td>\n",
       "      <td>83.535000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018611</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.404</td>\n",
       "      <td>1</td>\n",
       "      <td>38.646</td>\n",
       "      <td>47.690000</td>\n",
       "      <td>34.80600</td>\n",
       "      <td>29.202000</td>\n",
       "      <td>21.654000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "      <td>45.482786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018612</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.51200</td>\n",
       "      <td>34.657000</td>\n",
       "      <td>122.195000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018613</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>196.240</td>\n",
       "      <td>1</td>\n",
       "      <td>183.756</td>\n",
       "      <td>190.316000</td>\n",
       "      <td>172.97300</td>\n",
       "      <td>141.646000</td>\n",
       "      <td>93.817000</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.532227</td>\n",
       "      <td>-0.846602</td>\n",
       "      <td>False</td>\n",
       "      <td>89.681016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001094 rows × 241 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         county  is_business  product_type   target  is_consumption  \\\n",
       "11712         0            0             1    0.930               0   \n",
       "11713         0            0             1  123.214               1   \n",
       "11714         0            0             2    0.000               0   \n",
       "11715         0            0             2   21.940               1   \n",
       "11716         0            0             3    1.611               0   \n",
       "...         ...          ...           ...      ...             ...   \n",
       "2018609      15            1             0  197.233               1   \n",
       "2018610      15            1             1    0.000               0   \n",
       "2018611      15            1             1   28.404               1   \n",
       "2018612      15            1             3    0.000               0   \n",
       "2018613      15            1             3  196.240               1   \n",
       "\n",
       "         target_rt  target_lag_1h  target_lag_2h  target_lag_3h  \\\n",
       "11712        0.713     274.689353      274.69907     274.708302   \n",
       "11713       96.590     274.689353      274.69907     274.708302   \n",
       "11714        0.000     274.689353      274.69907     274.708302   \n",
       "11715       17.314     274.689353      274.69907     274.708302   \n",
       "11716        2.904     274.689353      274.69907     274.708302   \n",
       "...            ...            ...            ...            ...   \n",
       "2018609    184.072     171.092000      168.93300     174.920000   \n",
       "2018610      0.000       0.000000        2.50100      25.884000   \n",
       "2018611     38.646      47.690000       34.80600      29.202000   \n",
       "2018612      0.000       0.000000        4.51200      34.657000   \n",
       "2018613    183.756     190.316000      172.97300     141.646000   \n",
       "\n",
       "         target_lag_4h  ...  is_quarter_end  is_year_start  is_year_end  \\\n",
       "11712       274.717501  ...           False          False        False   \n",
       "11713       274.717501  ...           False          False        False   \n",
       "11714       274.717501  ...           False          False        False   \n",
       "11715       274.717501  ...           False          False        False   \n",
       "11716       274.717501  ...           False          False        False   \n",
       "...                ...  ...             ...            ...          ...   \n",
       "2018609     170.068000  ...           False          False        False   \n",
       "2018610      83.535000  ...           False          False        False   \n",
       "2018611      21.654000  ...           False          False        False   \n",
       "2018612     122.195000  ...           False          False        False   \n",
       "2018613      93.817000  ...           False          False        False   \n",
       "\n",
       "         season  hour_sin  hour_cos  day_of_year_sin  day_of_year_cos  \\\n",
       "11712         4  0.000000  1.000000        -0.894542        -0.446983   \n",
       "11713         4  0.000000  1.000000        -0.894542        -0.446983   \n",
       "11714         4  0.000000  1.000000        -0.894542        -0.446983   \n",
       "11715         4  0.000000  1.000000        -0.894542        -0.446983   \n",
       "11716         4  0.000000  1.000000        -0.894542        -0.446983   \n",
       "...         ...       ...       ...              ...              ...   \n",
       "2018609       2 -0.258819  0.965926         0.532227        -0.846602   \n",
       "2018610       2 -0.258819  0.965926         0.532227        -0.846602   \n",
       "2018611       2 -0.258819  0.965926         0.532227        -0.846602   \n",
       "2018612       2 -0.258819  0.965926         0.532227        -0.846602   \n",
       "2018613       2 -0.258819  0.965926         0.532227        -0.846602   \n",
       "\n",
       "         is_ee_holiday  target_installed_capacity  \n",
       "11712            False                   0.975978  \n",
       "11713            False                 129.305586  \n",
       "11714            False                   0.000000  \n",
       "11715            False                 131.850962  \n",
       "11716            False                   0.223505  \n",
       "...                ...                        ...  \n",
       "2018609          False                 318.117742  \n",
       "2018610          False                   0.000000  \n",
       "2018611          False                  45.482786  \n",
       "2018612          False                   0.000000  \n",
       "2018613          False                  89.681016  \n",
       "\n",
       "[2001094 rows x 241 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_no_na['target_installed_capacity'] = processed_df_no_na['target'] / processed_df_no_na['installed_capacity'] * 1000\n",
    "processed_df_no_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8fde4de-0a2b-46d8-818d-a7e1f0a047ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "cv_range = [('2022-09-10', '2023-05-31')]\n",
    "\n",
    "# Function to convert a date string into a datetime object\n",
    "def to_datetime(date_str):\n",
    "    return datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "# Converting the date strings in cv_ranges to datetime objects\n",
    "datetime_cv_ranges = [(to_datetime(start), to_datetime(end)) for start, end in cv_range]\n",
    "datetime_cv_ranges\n",
    "\n",
    "date_filter = data_processor.df_all_cols.date[processed_df_no_na.index]\n",
    "date_filter\n",
    "\n",
    "cv1_train = processed_df_no_na[date_filter <= datetime_cv_ranges[0][0]]\n",
    "cv1_test = processed_df_no_na[(date_filter <= datetime_cv_ranges[0][1]) & (date_filter > datetime_cv_ranges[0][0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad9f11cc-2af1-4b8f-9689-1deb717c2e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19 00:00:00\n",
      "2023-05-23 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "print(to_datetime('2023-04-05') + dt.timedelta(days=14))\n",
    "print(to_datetime('2023-04-05') + dt.timedelta(days=48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341bfe1-29cf-4b7b-abce-634f3f9f9b2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871c66a-fadc-4c18-bb3b-49e39b14f508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d6ec752-e0aa-4c32-bb95-3b12d7e4fb34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11712</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144249</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144250</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144251</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144252</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144253</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1129738 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  month  day\n",
       "11712    2021      9    5\n",
       "11713    2021      9    5\n",
       "11714    2021      9    5\n",
       "11715    2021      9    5\n",
       "11716    2021      9    5\n",
       "...       ...    ...  ...\n",
       "1144249  2022      9    1\n",
       "1144250  2022      9    1\n",
       "1144251  2022      9    1\n",
       "1144252  2022      9    1\n",
       "1144253  2022      9    1\n",
       "\n",
       "[1129738 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1_train[['year' ,'month', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2ceb22c-46e5-4245-bd27-45d32af655db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1144254</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144255</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144256</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144257</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144258</th>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315849</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315850</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315851</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315852</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315853</th>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  month  day\n",
       "1144254  2022      9    2\n",
       "1144255  2022      9    2\n",
       "1144256  2022      9    2\n",
       "1144257  2022      9    2\n",
       "1144258  2022      9    2\n",
       "...       ...    ...  ...\n",
       "1315849  2022     10   24\n",
       "1315850  2022     10   24\n",
       "1315851  2022     10   24\n",
       "1315852  2022     10   24\n",
       "1315853  2022     10   24\n",
       "\n",
       "[171264 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1_test[['year' ,'month', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01409cfe-bc1f-4652-85a8-51d754512f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11712</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018609</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018610</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018611</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018612</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018613</th>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001094 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  month  day\n",
       "11712    2021      9    5\n",
       "11713    2021      9    5\n",
       "11714    2021      9    5\n",
       "11715    2021      9    5\n",
       "11716    2021      9    5\n",
       "...       ...    ...  ...\n",
       "2018609  2023      5   31\n",
       "2018610  2023      5   31\n",
       "2018611  2023      5   31\n",
       "2018612  2023      5   31\n",
       "2018613  2023      5   31\n",
       "\n",
       "[2001094 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_no_na[['year', 'month', 'day']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42030eb-8db5-474f-8094-8ac676700c79",
   "metadata": {},
   "source": [
    "## Train 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9efe30dd-843e-4d58-a48b-29039218659e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a26d1777-6319-4ac7-8bb0-6f7500d955db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6c39eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "def inverse_tic(preds, train):\n",
    "    return preds/1000 * train.installed_capacity\n",
    "\n",
    "def train_cv(df):\n",
    "    for i in [0]:\n",
    "        train = df[date_filter <= datetime_cv_ranges[i][0]]\n",
    "        val = df[(date_filter <= datetime_cv_ranges[i][1]) & (date_filter > datetime_cv_ranges[i][0])]\n",
    "        print(f\"Fold {i}\")\n",
    "        print(f\"Train rows: {len(train)}\")\n",
    "        print(f\"Val rows: {len(val)}\")\n",
    "        \n",
    "        target_cols = ['target', 'target_installed_capacity']\n",
    "        drop_cols = ['target', 'target_installed_capacity', 'quarter', 'season', 'is_year_end', 'is_year_start', 'is_month_end', 'is_quarter_end', 'is_quarter_start', 'is_month_start', 'snowfall_hw_lagged', 'snowfall_hw_variances',\n",
    "                    'snowfall_fw', 'snowfall_hw_means']\n",
    "        \n",
    "        train = train.dropna()\n",
    "        val = val.dropna()\n",
    "        \n",
    "        df_train_target = train[target_cols]\n",
    "        df_train_data = train.drop(drop_cols, axis=1)\n",
    "        \n",
    "        df_val_target2 = val[target_cols]\n",
    "        df_val_data2 = val.drop(drop_cols, axis=1)\n",
    "        \n",
    "        cat_features = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", 'month', 'hour', 'quarter',\n",
    "               'day_of_week', 'is_weekend', 'is_month_start', 'is_month_end', 'is_quarter_start' ,'is_quarter_end', \n",
    "                'is_year_start', 'is_year_end', 'season'] + list(df_train_data.columns[df_train_data.columns.str.contains('is_na')])\n",
    "        cat_features = [c for c in cat_features if c in df_train_data.columns]  \n",
    "        \n",
    "        for feature in cat_features:\n",
    "            df_train_data[feature] = df_train_data[feature].astype('category')\n",
    "            df_val_data2[feature] = df_val_data2[feature].astype('category')\n",
    "        \n",
    "        \n",
    "        # We leave max_depth as -1\n",
    "        # Tune num_leaves, default is 31, let's double it       \n",
    "        \n",
    "        params = {'lambda_l1': 0.7466999841658806, 'lambda_l2': 3.2140838539606458, 'learning_rate': 0.13753679743025782, 'max_bin': 250, 'min_data_in_leaf': 150, 'n_estimators': 5593,  \n",
    "                'metric': 'mae', 'n_jobs': 22, 'boosting': 'dart', 'objective': 'tweedie', 'device':'gpu'}\n",
    "        \n",
    "        clf_consumer = LGBMRegressor(**params, random_state=42, verbose=1, )\n",
    "        \n",
    "        # clf_consumer = VotingRegressor([\n",
    "        #     ('lgb_0', LGBMRegressor(**params, random_state=42, verbose=1, )),\n",
    "        #     ('lgb_1', LGBMRegressor(**params, random_state=69, verbose=1, )),\n",
    "        #     ('lgb_2', LGBMRegressor(**params, random_state=1337, verbose=1, )), \n",
    "        #     ('lgb_3', LGBMRegressor(**params, random_state=124, verbose=1, )),\n",
    "        #     ('lgb_4', LGBMRegressor(**params, random_state=12351, verbose=1, ))\n",
    "        #     ], weights=[0.2,0.2,0.2,0.2,0.2])\n",
    "        \n",
    "        # clf_producer = VotingRegressor([\n",
    "        #     ('lgb_0', LGBMRegressor(**params, random_state=142, verbose=1, )),\n",
    "        #     ('lgb_1', LGBMRegressor(**params, random_state=169, verbose=1, )),\n",
    "        #     ('lgb_2', LGBMRegressor(**params, random_state=11337, verbose=1, )), \n",
    "        #     ('lgb_3', LGBMRegressor(**params, random_state=1124, verbose=1, )),\n",
    "        #     ('lgb_4', LGBMRegressor(**params, random_state=112351, verbose=1, ))\n",
    "        #     ], weights=[0.2,0.2,0.2,0.2,0.2])\n",
    "\n",
    "        clf_consumer.fit(df_train_data, df_train_target.target)\n",
    "        # clf_producer.fit(df_train_data[df_train_data.is_consumption==0], df_train_target[df_train_data.is_consumption==0].target)\n",
    "        \n",
    "        # clf_consumer = lgb.train(params_consumer, dtrain)\n",
    "        # preds = gbm.predict(df_val_data2)\n",
    "        # mae = mean_absolute_error(df_val_target2[\"target\"], preds)\n",
    "\n",
    "        y_pred = clf_consumer.predict(df_train_data)\n",
    "        # y_pred_producer = clf_producer.predict(df_train_data[df_train_data.is_consumption==0])\n",
    "        # y_pred2 = y_pred.copy()\n",
    "        # y_pred2[df_train_data.is_consumption==0] = y_pred_producer \n",
    "\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "        # Assuming you have two pandas Series: y_true and y_pred\n",
    "        mae = mean_absolute_error(df_train_target.target, y_pred)\n",
    "        print(f\" Train Mean Absolute Error_consumption:\", mae)\n",
    "        # mae = mean_absolute_error(df_train_target.target, y_pred2)\n",
    "        # print(f\" Train Mean w Producer Absolute Error:\", mae)\n",
    "\n",
    "        y_pred_val = clf_consumer.predict(df_val_data2)\n",
    "        # y_pred_val_producer = clf_producer.predict(df_val_data2[df_val_data2.is_consumption==0])\n",
    "        # y_pred_val2 = y_pred_val.copy()\n",
    "        # y_pred_val2[df_val_data2.is_consumption==0] = y_pred_val_producer \n",
    "\n",
    "        mae = mean_absolute_error(df_val_target2.target, y_pred_val)\n",
    "        print(\"Val Mean Absolute Error:\", mae)\n",
    "        # mae = mean_absolute_error(df_val_target2.target, y_pred_val2)\n",
    "        # print(\"Val Mean w Producer Absolute Error:\", mae)\n",
    "        \n",
    "        # importance = pd.DataFrame({'importance':clf2.feature_importances_, 'name':clf2.feature_name_})\n",
    "        # importance = importance.sort_values('importance', ascending=False)\n",
    "        # display(importance.head(30))\n",
    "        # display(importance.tail(30))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c236694-9a17-4b52-99aa-11a0344e0a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train rows: 1158538\n",
      "Val rows: 842556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50105\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.083818 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 19.971073246380257\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 53.30573576733588\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_cv(processed_df_no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "962b343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "def inverse_tic(preds, train):\n",
    "    return preds/1000 * train.installed_capacity\n",
    "\n",
    "def train_cv(df):\n",
    "    for i in [0]:\n",
    "        train = df[date_filter <= datetime_cv_ranges[i][0]]\n",
    "        val = df[(date_filter <= datetime_cv_ranges[i][1]) & (date_filter > datetime_cv_ranges[i][0])]\n",
    "        print(f\"Fold {i}\")\n",
    "        print(f\"Train rows: {len(train)}\")\n",
    "        print(f\"Val rows: {len(val)}\")\n",
    "        \n",
    "        target_cols = ['target', 'target_installed_capacity']\n",
    "        drop_cols = ['target', 'target_installed_capacity', 'quarter', 'season', 'is_year_end', 'is_year_start', 'is_month_end', 'is_quarter_end', 'is_quarter_start', 'is_month_start', 'snowfall_hw_lagged', 'snowfall_hw_variances',\n",
    "                    'snowfall_fw', 'snowfall_hw_means']\n",
    "        \n",
    "        train = train.dropna()\n",
    "        val = val.dropna()\n",
    "        \n",
    "        df_train_target = train[target_cols]\n",
    "        df_train_data = train.drop(drop_cols, axis=1)\n",
    "        \n",
    "        df_val_target2 = val[target_cols]\n",
    "        df_val_data2 = val.drop(drop_cols, axis=1)\n",
    "        \n",
    "        cat_features = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", 'month', 'hour', 'quarter',\n",
    "               'day_of_week', 'is_weekend', 'is_month_start', 'is_month_end', 'is_quarter_start' ,'is_quarter_end', \n",
    "                'is_year_start', 'is_year_end', 'season'] + list(df_train_data.columns[df_train_data.columns.str.contains('is_na')])\n",
    "        cat_features = [c for c in cat_features if c in df_train_data.columns]  \n",
    "        \n",
    "        for feature in cat_features:\n",
    "            df_train_data[feature] = df_train_data[feature].astype('category')\n",
    "            df_val_data2[feature] = df_val_data2[feature].astype('category')\n",
    "        \n",
    "        \n",
    "        # We leave max_depth as -1\n",
    "        # Tune num_leaves, default is 31, let's double it       \n",
    "        \n",
    "        params = {'lambda_l1': 0.7466999841658806, 'lambda_l2': 3.2140838539606458, 'learning_rate': 0.13753679743025782, 'max_bin': 250, 'min_data_in_leaf': 150, 'n_estimators': 5593,  \n",
    "                'metric': 'mae', 'n_jobs': 22, 'boosting': 'dart', 'objective': 'tweedie', 'device':'gpu'}\n",
    "        \n",
    "        # clf_consumer = LGBMRegressor(**params, random_state=42, verbose=1, )\n",
    "        \n",
    "        clf_consumer = VotingRegressor([\n",
    "            ('lgb_0', LGBMRegressor(**params, random_state=42, verbose=1, )),\n",
    "            ('lgb_1', LGBMRegressor(**params, random_state=69, verbose=1, )),\n",
    "            ('lgb_2', LGBMRegressor(**params, random_state=1337, verbose=1, )), \n",
    "            ('lgb_3', LGBMRegressor(**params, random_state=124, verbose=1, )),\n",
    "            ('lgb_4', LGBMRegressor(**params, random_state=12351, verbose=1, ))\n",
    "            ], weights=[0.2,0.2,0.2,0.2,0.2])\n",
    "        \n",
    "        # clf_producer = VotingRegressor([\n",
    "        #     ('lgb_0', LGBMRegressor(**params, random_state=142, verbose=1, )),\n",
    "        #     ('lgb_1', LGBMRegressor(**params, random_state=169, verbose=1, )),\n",
    "        #     ('lgb_2', LGBMRegressor(**params, random_state=11337, verbose=1, )), \n",
    "        #     ('lgb_3', LGBMRegressor(**params, random_state=1124, verbose=1, )),\n",
    "        #     ('lgb_4', LGBMRegressor(**params, random_state=112351, verbose=1, ))\n",
    "        #     ], weights=[0.2,0.2,0.2,0.2,0.2])\n",
    "\n",
    "        clf_consumer.fit(df_train_data, df_train_target.target)\n",
    "        # clf_producer.fit(df_train_data[df_train_data.is_consumption==0], df_train_target[df_train_data.is_consumption==0].target)\n",
    "        \n",
    "        # clf_consumer = lgb.train(params_consumer, dtrain)\n",
    "        # preds = gbm.predict(df_val_data2)\n",
    "        # mae = mean_absolute_error(df_val_target2[\"target\"], preds)\n",
    "\n",
    "        y_pred = clf_consumer.predict(df_train_data)\n",
    "        # y_pred_producer = clf_producer.predict(df_train_data[df_train_data.is_consumption==0])\n",
    "        # y_pred2 = y_pred.copy()\n",
    "        # y_pred2[df_train_data.is_consumption==0] = y_pred_producer \n",
    "\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "        # Assuming you have two pandas Series: y_true and y_pred\n",
    "        mae = mean_absolute_error(df_train_target.target, y_pred)\n",
    "        print(f\" Train Mean Absolute Error_consumption:\", mae)\n",
    "        # mae = mean_absolute_error(df_train_target.target, y_pred2)\n",
    "        # print(f\" Train Mean w Producer Absolute Error:\", mae)\n",
    "\n",
    "        y_pred_val = clf_consumer.predict(df_val_data2)\n",
    "        # y_pred_val_producer = clf_producer.predict(df_val_data2[df_val_data2.is_consumption==0])\n",
    "        # y_pred_val2 = y_pred_val.copy()\n",
    "        # y_pred_val2[df_val_data2.is_consumption==0] = y_pred_val_producer \n",
    "\n",
    "        mae = mean_absolute_error(df_val_target2.target, y_pred_val)\n",
    "        print(\"Val Mean Absolute Error:\", mae)\n",
    "        # mae = mean_absolute_error(df_val_target2.target, y_pred_val2)\n",
    "        # print(\"Val Mean w Producer Absolute Error:\", mae)\n",
    "        \n",
    "        # importance = pd.DataFrame({'importance':clf2.feature_importances_, 'name':clf2.feature_name_})\n",
    "        # importance = importance.sort_values('importance', ascending=False)\n",
    "        # display(importance.head(30))\n",
    "        # display(importance.tail(30))\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00681bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Train rows: 1158538\n",
      "Val rows: 842556\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50105\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.069642 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50105\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.069387 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50098\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.074093 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50101\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.068989 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 50118\n",
      "[LightGBM] [Info] Number of data points in the train set: 1158538, number of used features: 225\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3090, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 214 dense feature groups (238.65 MB) transferred to GPU in 0.076105 secs. 1 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 5.525093\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 19.716214884140374\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 52.74843411098012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_cv(processed_df_no_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f72595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, period 0\n",
      "Train rows: 1158538\n",
      "Val rows: 45024\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 19.989653220697605\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 40.652205814864864\n",
      "Fold 0, period 1\n",
      "Train rows: 1203562\n",
      "Val rows: 45216\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.347719945564297\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 42.98285403745325\n",
      "Fold 0, period 2\n",
      "Train rows: 1248778\n",
      "Val rows: 45696\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.658602003856235\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 34.216833621222904\n",
      "Fold 0, period 3\n",
      "Train rows: 1294474\n",
      "Val rows: 45744\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.79129727362206\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 33.68042353009938\n",
      "Fold 0, period 4\n",
      "Train rows: 1340218\n",
      "Val rows: 46368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.857936482403268\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 28.51478033731072\n",
      "Fold 0, period 5\n",
      "Train rows: 1386586\n",
      "Val rows: 46032\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.963167573092036\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 33.55619960979711\n",
      "Fold 0, period 6\n",
      "Train rows: 1432618\n",
      "Val rows: 44976\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.059694606043337\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 29.034764758801163\n",
      "Fold 0, period 7\n",
      "Train rows: 1477594\n",
      "Val rows: 45024\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.00812404796966\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 30.170009768703046\n",
      "Fold 0, period 8\n",
      "Train rows: 1522618\n",
      "Val rows: 45024\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.894843057617614\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 41.88988105318192\n",
      "Fold 0, period 9\n",
      "Train rows: 1567642\n",
      "Val rows: 44544\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.92560825748033\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 26.864562511460385\n",
      "Fold 0, period 10\n",
      "Train rows: 1612186\n",
      "Val rows: 44688\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 20.994408740781324\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 26.67792694491294\n",
      "Fold 0, period 11\n",
      "Train rows: 1656874\n",
      "Val rows: 44544\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.045617010076356\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 32.042213304981516\n",
      "Fold 0, period 12\n",
      "Train rows: 1701418\n",
      "Val rows: 44400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.227290530541886\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 53.96121283264384\n",
      "Fold 0, period 13\n",
      "Train rows: 1745818\n",
      "Val rows: 44352\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.47487560795318\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 58.94530507824923\n",
      "Fold 0, period 14\n",
      "Train rows: 1790170\n",
      "Val rows: 43740\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 21.843069745852087\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 60.27376631815525\n",
      "Fold 0, period 15\n",
      "Train rows: 1833910\n",
      "Val rows: 43392\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 22.13656605151642\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 51.23739340606911\n",
      "Fold 0, period 16\n",
      "Train rows: 1877302\n",
      "Val rows: 43584\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 22.52660781160749\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 64.79589411569764\n",
      "Fold 0, period 17\n",
      "Train rows: 1920886\n",
      "Val rows: 45360\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      " Train Mean Absolute Error_consumption: 22.97288701521\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=150, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=150\n",
      "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7466999841658806, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7466999841658806\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.2140838539606458, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.2140838539606458\n",
      "Val Mean Absolute Error: 60.74173166968084\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_pred_list = []\n",
    "train_mae_list = []\n",
    "train_targets_list = []\n",
    "\n",
    "pred_list = []\n",
    "mae_list = []\n",
    "val_targets_list = []\n",
    "\n",
    "df = processed_df_no_na\n",
    "i=0\n",
    "for f in range(((datetime_cv_ranges[i][1] - datetime_cv_ranges[i][0]).days//14)):\n",
    "    start = datetime_cv_ranges[i][0] + dt.timedelta(days=f*14)\n",
    "    stop = datetime_cv_ranges[i][0] + dt.timedelta(days=(f+1)*14)\n",
    "    train = processed_df_no_na[date_filter <= start]\n",
    "    val = processed_df_no_na[(date_filter <= stop) & (date_filter > start)]\n",
    "    \n",
    "    print(f\"Fold {i}, period {f}\")\n",
    "    print(f\"Train rows: {len(train)}\")\n",
    "    print(f\"Val rows: {len(val)}\")\n",
    "\n",
    "    target_cols = ['target', 'target_installed_capacity']\n",
    "    drop_cols = ['target', 'target_installed_capacity', 'quarter', 'season', 'is_year_end', 'is_year_start', 'is_month_end', 'is_quarter_end', 'is_quarter_start', 'is_month_start', 'snowfall_hw_lagged', 'snowfall_hw_variances',\n",
    "                'snowfall_fw', 'snowfall_hw_means']\n",
    "\n",
    "    df_train_target = train[target_cols]\n",
    "    df_train_data = train.drop(drop_cols, axis=1)\n",
    "\n",
    "    df_val_target2 = val[target_cols]\n",
    "    df_val_data2 = val.drop(drop_cols, axis=1)\n",
    "\n",
    "    cat_features = [\"county\", \"is_business\", \"product_type\", \"is_consumption\", 'month', 'hour', 'quarter',\n",
    "           'day_of_week', 'is_weekend', 'is_month_start', 'is_month_end', 'is_quarter_start' ,'is_quarter_end', \n",
    "            'is_year_start', 'is_year_end', 'season'] + list(df_train_data.columns[df_train_data.columns.str.contains('is_na')])\n",
    "    cat_features = [c for c in cat_features if c in df_train_data.columns]\n",
    "\n",
    "    # We leave max_depth as -1\n",
    "    # Tune num_leaves, default is 31, let's double it       \n",
    "\n",
    "    params = {'lambda_l1': 0.7466999841658806, 'lambda_l2': 3.2140838539606458, 'learning_rate': 0.13753679743025782, 'max_bin': 250, 'min_data_in_leaf': 150, 'n_estimators': 5593,  \n",
    "                'metric': 'mae', 'n_jobs': 22, 'boosting': 'dart', 'objective': 'tweedie', 'device':'gpu'}\n",
    "    \n",
    "    clf = LGBMRegressor(**params, random_state=42, verbose=0, importance_type='gain')\n",
    "\n",
    "    clf.fit(df_train_data, df_train_target.target, categorical_feature=cat_features)\n",
    "\n",
    "    y_pred = clf.predict(df_train_data)\n",
    "    train_pred_list.append(y_pred)\n",
    "\n",
    "    from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "    # Assuming you have two pandas Series: y_true and y_pred\n",
    "    mae = mean_absolute_error(df_train_target.target, y_pred)\n",
    "    train_mae_list.append(mae)\n",
    "    train_targets_list.append(df_train_target.target)\n",
    "    print(f\" Train Mean Absolute Error_consumption:\", mae)\n",
    "\n",
    "    y_pred_val = clf.predict(df_val_data2)\n",
    "    pred_list.append(y_pred_val)\n",
    "\n",
    "    mae = mean_absolute_error(df_val_target2.target, y_pred_val)\n",
    "    val_targets_list.append(df_val_target2.target)\n",
    "    mae_list.append(mae)\n",
    "    print(\"Val Mean Absolute Error:\", mae)\n",
    "\n",
    "# importance = pd.DataFrame({'importance':clf2.feature_importances_, 'name':clf2.feature_name_})\n",
    "# importance = importance.sort_values('importance', ascending=False)\n",
    "# display(importance.head(30))\n",
    "# display(importance.tail(30))\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6819b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.6798865951825"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mae_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf85cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
